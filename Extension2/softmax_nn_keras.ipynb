{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits # The MNIST data set is in scikit learn data set\n",
    "from sklearn.preprocessing import StandardScaler  # It is important in neural networks to scale the date\n",
    "from sklearn.model_selection import train_test_split  # The standard - train/test to prevent overfitting and choose hyperparameters\n",
    "from sklearn.metrics import accuracy_score # \n",
    "import numpy as np\n",
    "import numpy.random as r # We will randomly initialize our weights\n",
    "import matplotlib.pyplot as plt \n",
    "from math import exp"
   ]
  },
  {
   "source": [
    "# NN no extension (Digits dataset)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits=load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "X_scale = StandardScaler()\n",
    "X = X_scale.fit_transform(digits.data)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_y_to_vect(y):\n",
    "    y_vect = np.zeros((len(y), 10))\n",
    "    for i in range(len(y)):\n",
    "        y_vect[i, y[i]] = 1\n",
    "    return y_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert digits to vectors\n",
    "y_v_train = convert_y_to_vect(y_train)\n",
    "y_v_test = convert_y_to_vect(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation=\"sigmoid\"))\n",
    "model.add(Dense(30, activation = \"sigmoid\"))\n",
    "model.add(Dense(10, activation = \"sigmoid\"))\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.1570 - accuracy: 0.0946\n",
      "Epoch 2/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.1002 - accuracy: 0.1327\n",
      "Epoch 3/120\n",
      "1078/1078 [==============================] - 2s 1ms/step - loss: 0.0929 - accuracy: 0.1605\n",
      "Epoch 4/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0909 - accuracy: 0.1512\n",
      "Epoch 5/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0902 - accuracy: 0.1568\n",
      "Epoch 6/120\n",
      "1078/1078 [==============================] - 1s 826us/step - loss: 0.0898 - accuracy: 0.1577\n",
      "Epoch 7/120\n",
      "1078/1078 [==============================] - 1s 862us/step - loss: 0.0896 - accuracy: 0.1660\n",
      "Epoch 8/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0894 - accuracy: 0.1660\n",
      "Epoch 9/120\n",
      "1078/1078 [==============================] - 1s 967us/step - loss: 0.0893 - accuracy: 0.1781\n",
      "Epoch 10/120\n",
      "1078/1078 [==============================] - 1s 606us/step - loss: 0.0892 - accuracy: 0.1837\n",
      "Epoch 11/120\n",
      "1078/1078 [==============================] - 1s 847us/step - loss: 0.0892 - accuracy: 0.1781\n",
      "Epoch 12/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0891 - accuracy: 0.1939\n",
      "Epoch 13/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0890 - accuracy: 0.1818\n",
      "Epoch 14/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0890 - accuracy: 0.2022\n",
      "Epoch 15/120\n",
      "1078/1078 [==============================] - 1s 645us/step - loss: 0.0889 - accuracy: 0.2004\n",
      "Epoch 16/120\n",
      "1078/1078 [==============================] - 1s 642us/step - loss: 0.0888 - accuracy: 0.2208\n",
      "Epoch 17/120\n",
      "1078/1078 [==============================] - 1s 993us/step - loss: 0.0887 - accuracy: 0.2152\n",
      "Epoch 18/120\n",
      "1078/1078 [==============================] - 1s 683us/step - loss: 0.0887 - accuracy: 0.2263\n",
      "Epoch 19/120\n",
      "1078/1078 [==============================] - 1s 788us/step - loss: 0.0886 - accuracy: 0.2226\n",
      "Epoch 20/120\n",
      "1078/1078 [==============================] - 1s 863us/step - loss: 0.0885 - accuracy: 0.2273\n",
      "Epoch 21/120\n",
      "1078/1078 [==============================] - 1s 596us/step - loss: 0.0884 - accuracy: 0.2338\n",
      "Epoch 22/120\n",
      "1078/1078 [==============================] - 1s 612us/step - loss: 0.0884 - accuracy: 0.2375\n",
      "Epoch 23/120\n",
      "1078/1078 [==============================] - 1s 614us/step - loss: 0.0883 - accuracy: 0.2412\n",
      "Epoch 24/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0882 - accuracy: 0.2579\n",
      "Epoch 25/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0881 - accuracy: 0.2662\n",
      "Epoch 26/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0880 - accuracy: 0.2644\n",
      "Epoch 27/120\n",
      "1078/1078 [==============================] - 1s 977us/step - loss: 0.0879 - accuracy: 0.2746\n",
      "Epoch 28/120\n",
      "1078/1078 [==============================] - 2s 1ms/step - loss: 0.0878 - accuracy: 0.2820\n",
      "Epoch 29/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0878 - accuracy: 0.2829\n",
      "Epoch 30/120\n",
      "1078/1078 [==============================] - 2s 1ms/step - loss: 0.0877 - accuracy: 0.2792\n",
      "Epoch 31/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0876 - accuracy: 0.2913\n",
      "Epoch 32/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0875 - accuracy: 0.2894\n",
      "Epoch 33/120\n",
      "1078/1078 [==============================] - 1s 760us/step - loss: 0.0874 - accuracy: 0.2987\n",
      "Epoch 34/120\n",
      "1078/1078 [==============================] - 1s 644us/step - loss: 0.0872 - accuracy: 0.3043\n",
      "Epoch 35/120\n",
      "1078/1078 [==============================] - 1s 949us/step - loss: 0.0871 - accuracy: 0.3052\n",
      "Epoch 36/120\n",
      "1078/1078 [==============================] - 1s 759us/step - loss: 0.0870 - accuracy: 0.3173\n",
      "Epoch 37/120\n",
      "1078/1078 [==============================] - 1s 741us/step - loss: 0.0869 - accuracy: 0.3284\n",
      "Epoch 38/120\n",
      "1078/1078 [==============================] - 1s 678us/step - loss: 0.0868 - accuracy: 0.3275\n",
      "Epoch 39/120\n",
      "1078/1078 [==============================] - 1s 730us/step - loss: 0.0867 - accuracy: 0.3358\n",
      "Epoch 40/120\n",
      "1078/1078 [==============================] - 1s 751us/step - loss: 0.0865 - accuracy: 0.3340\n",
      "Epoch 41/120\n",
      "1078/1078 [==============================] - 1s 741us/step - loss: 0.0864 - accuracy: 0.3404\n",
      "Epoch 42/120\n",
      "1078/1078 [==============================] - 1s 721us/step - loss: 0.0863 - accuracy: 0.3377\n",
      "Epoch 43/120\n",
      "1078/1078 [==============================] - 1s 856us/step - loss: 0.0861 - accuracy: 0.3534\n",
      "Epoch 44/120\n",
      "1078/1078 [==============================] - 1s 954us/step - loss: 0.0860 - accuracy: 0.3432\n",
      "Epoch 45/120\n",
      "1078/1078 [==============================] - 1s 785us/step - loss: 0.0858 - accuracy: 0.3386\n",
      "Epoch 46/120\n",
      "1078/1078 [==============================] - 1s 823us/step - loss: 0.0857 - accuracy: 0.3321\n",
      "Epoch 47/120\n",
      "1078/1078 [==============================] - 1s 783us/step - loss: 0.0855 - accuracy: 0.3479\n",
      "Epoch 48/120\n",
      "1078/1078 [==============================] - 1s 917us/step - loss: 0.0853 - accuracy: 0.3525\n",
      "Epoch 49/120\n",
      "1078/1078 [==============================] - 1s 717us/step - loss: 0.0852 - accuracy: 0.3525\n",
      "Epoch 50/120\n",
      "1078/1078 [==============================] - 1s 736us/step - loss: 0.0850 - accuracy: 0.3627\n",
      "Epoch 51/120\n",
      "1078/1078 [==============================] - 1s 685us/step - loss: 0.0848 - accuracy: 0.3673\n",
      "Epoch 52/120\n",
      "1078/1078 [==============================] - 1s 690us/step - loss: 0.0846 - accuracy: 0.3544\n",
      "Epoch 53/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0844 - accuracy: 0.3655\n",
      "Epoch 54/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0842 - accuracy: 0.3692\n",
      "Epoch 55/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0840 - accuracy: 0.3562\n",
      "Epoch 56/120\n",
      "1078/1078 [==============================] - 2s 1ms/step - loss: 0.0838 - accuracy: 0.3692\n",
      "Epoch 57/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0836 - accuracy: 0.3738\n",
      "Epoch 58/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0833 - accuracy: 0.3757\n",
      "Epoch 59/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0831 - accuracy: 0.3729\n",
      "Epoch 60/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0829 - accuracy: 0.3831\n",
      "Epoch 61/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0826 - accuracy: 0.3766\n",
      "Epoch 62/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0824 - accuracy: 0.3970\n",
      "Epoch 63/120\n",
      "1078/1078 [==============================] - 2s 1ms/step - loss: 0.0821 - accuracy: 0.3850\n",
      "Epoch 64/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0818 - accuracy: 0.4017\n",
      "Epoch 65/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0816 - accuracy: 0.3970\n",
      "Epoch 66/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0813 - accuracy: 0.4017\n",
      "Epoch 67/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0810 - accuracy: 0.4026\n",
      "Epoch 68/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0807 - accuracy: 0.4109\n",
      "Epoch 69/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0804 - accuracy: 0.4137\n",
      "Epoch 70/120\n",
      "1078/1078 [==============================] - 2s 1ms/step - loss: 0.0801 - accuracy: 0.4202\n",
      "Epoch 71/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0798 - accuracy: 0.4341\n",
      "Epoch 72/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0795 - accuracy: 0.4295\n",
      "Epoch 73/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0791 - accuracy: 0.4341\n",
      "Epoch 74/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0788 - accuracy: 0.4564\n",
      "Epoch 75/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0785 - accuracy: 0.4332\n",
      "Epoch 76/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0781 - accuracy: 0.4564\n",
      "Epoch 77/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0778 - accuracy: 0.4666\n",
      "Epoch 78/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0774 - accuracy: 0.4759\n",
      "Epoch 79/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0771 - accuracy: 0.4666\n",
      "Epoch 80/120\n",
      "1078/1078 [==============================] - 1s 823us/step - loss: 0.0767 - accuracy: 0.4731\n",
      "Epoch 81/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0764 - accuracy: 0.4907\n",
      "Epoch 82/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0760 - accuracy: 0.4907\n",
      "Epoch 83/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0756 - accuracy: 0.5056\n",
      "Epoch 84/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0752 - accuracy: 0.5037\n",
      "Epoch 85/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0748 - accuracy: 0.5121\n",
      "Epoch 86/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0744 - accuracy: 0.5121\n",
      "Epoch 87/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0740 - accuracy: 0.5213\n",
      "Epoch 88/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0736 - accuracy: 0.5288\n",
      "Epoch 89/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0732 - accuracy: 0.5288\n",
      "Epoch 90/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0728 - accuracy: 0.5436\n",
      "Epoch 91/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0724 - accuracy: 0.5390\n",
      "Epoch 92/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0719 - accuracy: 0.5529\n",
      "Epoch 93/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0715 - accuracy: 0.5538\n",
      "Epoch 94/120\n",
      "1078/1078 [==============================] - 2s 1ms/step - loss: 0.0711 - accuracy: 0.5677\n",
      "Epoch 95/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0706 - accuracy: 0.5853\n",
      "Epoch 96/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0702 - accuracy: 0.5807\n",
      "Epoch 97/120\n",
      "1078/1078 [==============================] - 2s 1ms/step - loss: 0.0697 - accuracy: 0.5872\n",
      "Epoch 98/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0692 - accuracy: 0.5909\n",
      "Epoch 99/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0688 - accuracy: 0.5937\n",
      "Epoch 100/120\n",
      "1078/1078 [==============================] - 2s 1ms/step - loss: 0.0683 - accuracy: 0.6113\n",
      "Epoch 101/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0678 - accuracy: 0.6122\n",
      "Epoch 102/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0674 - accuracy: 0.6122\n",
      "Epoch 103/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0669 - accuracy: 0.6308\n",
      "Epoch 104/120\n",
      "1078/1078 [==============================] - 2s 1ms/step - loss: 0.0664 - accuracy: 0.6364\n",
      "Epoch 105/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0659 - accuracy: 0.6336\n",
      "Epoch 106/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0654 - accuracy: 0.6382\n",
      "Epoch 107/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0650 - accuracy: 0.6447\n",
      "Epoch 108/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0645 - accuracy: 0.6540\n",
      "Epoch 109/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0640 - accuracy: 0.6521\n",
      "Epoch 110/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0635 - accuracy: 0.6614\n",
      "Epoch 111/120\n",
      "1078/1078 [==============================] - 2s 1ms/step - loss: 0.0630 - accuracy: 0.6642\n",
      "Epoch 112/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0625 - accuracy: 0.6679\n",
      "Epoch 113/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0620 - accuracy: 0.6827\n",
      "Epoch 114/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0616 - accuracy: 0.6716\n",
      "Epoch 115/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0611 - accuracy: 0.6818\n",
      "Epoch 116/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0606 - accuracy: 0.6939\n",
      "Epoch 117/120\n",
      "1078/1078 [==============================] - 2s 1ms/step - loss: 0.0601 - accuracy: 0.6985\n",
      "Epoch 118/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0597 - accuracy: 0.6976\n",
      "Epoch 119/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0592 - accuracy: 0.7069\n",
      "Epoch 120/120\n",
      "1078/1078 [==============================] - 2s 1ms/step - loss: 0.0587 - accuracy: 0.7106\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13ccc6580>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "model.fit(X_train, y_v_train, epochs = 120, batch_size = 1)"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0596 - accuracy: 0.6690\n",
      "Accuracy: 66.90\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(X_test, y_v_test)\n",
    "print('Accuracy: %.2f' % (accuracy[1]*100))"
   ]
  },
  {
   "source": [
    "# NN with Softmax extension (Digits dataset)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_model = Sequential()\n",
    "softmax_model.add(Dense(64, activation=\"sigmoid\"))\n",
    "softmax_model.add(Dense(30, activation = \"sigmoid\"))\n",
    "softmax_model.add(Dense(10, activation = \"softmax\"))\n",
    "softmax_model.compile(loss='mean_squared_error', optimizer='sgd', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0582 - accuracy: 0.7096\n",
      "Epoch 2/120\n",
      "1078/1078 [==============================] - 1s 987us/step - loss: 0.0578 - accuracy: 0.7180\n",
      "Epoch 3/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0573 - accuracy: 0.7161\n",
      "Epoch 4/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0569 - accuracy: 0.7236\n",
      "Epoch 5/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0564 - accuracy: 0.7282\n",
      "Epoch 6/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0560 - accuracy: 0.7273\n",
      "Epoch 7/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0555 - accuracy: 0.7310\n",
      "Epoch 8/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0551 - accuracy: 0.7310\n",
      "Epoch 9/120\n",
      "1078/1078 [==============================] - 2s 1ms/step - loss: 0.0546 - accuracy: 0.7375\n",
      "Epoch 10/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0542 - accuracy: 0.7356\n",
      "Epoch 11/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0538 - accuracy: 0.7421\n",
      "Epoch 12/120\n",
      "1078/1078 [==============================] - 1s 966us/step - loss: 0.0533 - accuracy: 0.7421\n",
      "Epoch 13/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0529 - accuracy: 0.7477\n",
      "Epoch 14/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0525 - accuracy: 0.7532\n",
      "Epoch 15/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0521 - accuracy: 0.7588\n",
      "Epoch 16/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0517 - accuracy: 0.7662\n",
      "Epoch 17/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0513 - accuracy: 0.7690\n",
      "Epoch 18/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0509 - accuracy: 0.7727\n",
      "Epoch 19/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0505 - accuracy: 0.7746\n",
      "Epoch 20/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0501 - accuracy: 0.7764\n",
      "Epoch 21/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0497 - accuracy: 0.7839\n",
      "Epoch 22/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0493 - accuracy: 0.7829\n",
      "Epoch 23/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0489 - accuracy: 0.7894\n",
      "Epoch 24/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0485 - accuracy: 0.7885\n",
      "Epoch 25/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0481 - accuracy: 0.7931\n",
      "Epoch 26/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0477 - accuracy: 0.7941\n",
      "Epoch 27/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0474 - accuracy: 0.7950\n",
      "Epoch 28/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0470 - accuracy: 0.7959\n",
      "Epoch 29/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0466 - accuracy: 0.7978\n",
      "Epoch 30/120\n",
      "1078/1078 [==============================] - 2s 1ms/step - loss: 0.0462 - accuracy: 0.7987\n",
      "Epoch 31/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0459 - accuracy: 0.8043\n",
      "Epoch 32/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0455 - accuracy: 0.8015\n",
      "Epoch 33/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0452 - accuracy: 0.8071\n",
      "Epoch 34/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0448 - accuracy: 0.8071\n",
      "Epoch 35/120\n",
      "1078/1078 [==============================] - 1s 989us/step - loss: 0.0445 - accuracy: 0.8126\n",
      "Epoch 36/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0441 - accuracy: 0.8145\n",
      "Epoch 37/120\n",
      "1078/1078 [==============================] - 2s 1ms/step - loss: 0.0438 - accuracy: 0.8173\n",
      "Epoch 38/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0434 - accuracy: 0.8237\n",
      "Epoch 39/120\n",
      "1078/1078 [==============================] - 2s 1ms/step - loss: 0.0431 - accuracy: 0.8275\n",
      "Epoch 40/120\n",
      "1078/1078 [==============================] - 1s 983us/step - loss: 0.0428 - accuracy: 0.8330\n",
      "Epoch 41/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0424 - accuracy: 0.8321\n",
      "Epoch 42/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0421 - accuracy: 0.8330\n",
      "Epoch 43/120\n",
      "1078/1078 [==============================] - 1s 726us/step - loss: 0.0418 - accuracy: 0.8395\n",
      "Epoch 44/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0414 - accuracy: 0.8442\n",
      "Epoch 45/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0411 - accuracy: 0.8451\n",
      "Epoch 46/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0408 - accuracy: 0.8479\n",
      "Epoch 47/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0405 - accuracy: 0.8516\n",
      "Epoch 48/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0402 - accuracy: 0.8525\n",
      "Epoch 49/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0399 - accuracy: 0.8571\n",
      "Epoch 50/120\n",
      "1078/1078 [==============================] - 1s 912us/step - loss: 0.0396 - accuracy: 0.8553\n",
      "Epoch 51/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0393 - accuracy: 0.8618\n",
      "Epoch 52/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0390 - accuracy: 0.8636\n",
      "Epoch 53/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0387 - accuracy: 0.8618\n",
      "Epoch 54/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0384 - accuracy: 0.8655\n",
      "Epoch 55/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0381 - accuracy: 0.8711\n",
      "Epoch 56/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0378 - accuracy: 0.8701\n",
      "Epoch 57/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0375 - accuracy: 0.8748\n",
      "Epoch 58/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0372 - accuracy: 0.8692\n",
      "Epoch 59/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0369 - accuracy: 0.8776\n",
      "Epoch 60/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0366 - accuracy: 0.8766\n",
      "Epoch 61/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0364 - accuracy: 0.8785\n",
      "Epoch 62/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0361 - accuracy: 0.8785\n",
      "Epoch 63/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0358 - accuracy: 0.8785\n",
      "Epoch 64/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0356 - accuracy: 0.8813\n",
      "Epoch 65/120\n",
      "1078/1078 [==============================] - 2s 1ms/step - loss: 0.0353 - accuracy: 0.8850\n",
      "Epoch 66/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0350 - accuracy: 0.8850\n",
      "Epoch 67/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0348 - accuracy: 0.8850\n",
      "Epoch 68/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0345 - accuracy: 0.8868\n",
      "Epoch 69/120\n",
      "1078/1078 [==============================] - 3s 3ms/step - loss: 0.0343 - accuracy: 0.8868\n",
      "Epoch 70/120\n",
      "1078/1078 [==============================] - 3s 3ms/step - loss: 0.0340 - accuracy: 0.8868\n",
      "Epoch 71/120\n",
      "1078/1078 [==============================] - 4s 3ms/step - loss: 0.0337 - accuracy: 0.8887\n",
      "Epoch 72/120\n",
      "1078/1078 [==============================] - 4s 3ms/step - loss: 0.0335 - accuracy: 0.8924\n",
      "Epoch 73/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0333 - accuracy: 0.8952\n",
      "Epoch 74/120\n",
      "1078/1078 [==============================] - 3s 3ms/step - loss: 0.0330 - accuracy: 0.8970\n",
      "Epoch 75/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0328 - accuracy: 0.8970\n",
      "Epoch 76/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0325 - accuracy: 0.8970\n",
      "Epoch 77/120\n",
      "1078/1078 [==============================] - 1s 999us/step - loss: 0.0323 - accuracy: 0.8989\n",
      "Epoch 78/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0321 - accuracy: 0.8998\n",
      "Epoch 79/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0318 - accuracy: 0.8998\n",
      "Epoch 80/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0316 - accuracy: 0.9026\n",
      "Epoch 81/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0314 - accuracy: 0.9017\n",
      "Epoch 82/120\n",
      "1078/1078 [==============================] - 2s 2ms/step - loss: 0.0311 - accuracy: 0.9045\n",
      "Epoch 83/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0309 - accuracy: 0.9054\n",
      "Epoch 84/120\n",
      "1078/1078 [==============================] - 1s 874us/step - loss: 0.0307 - accuracy: 0.9026\n",
      "Epoch 85/120\n",
      "1078/1078 [==============================] - 1s 816us/step - loss: 0.0305 - accuracy: 0.9063\n",
      "Epoch 86/120\n",
      "1078/1078 [==============================] - 1s 911us/step - loss: 0.0303 - accuracy: 0.9072\n",
      "Epoch 87/120\n",
      "1078/1078 [==============================] - 1s 770us/step - loss: 0.0300 - accuracy: 0.9082\n",
      "Epoch 88/120\n",
      "1078/1078 [==============================] - 1s 811us/step - loss: 0.0298 - accuracy: 0.9109\n",
      "Epoch 89/120\n",
      "1078/1078 [==============================] - 1s 808us/step - loss: 0.0296 - accuracy: 0.9119\n",
      "Epoch 90/120\n",
      "1078/1078 [==============================] - 1s 803us/step - loss: 0.0294 - accuracy: 0.9128\n",
      "Epoch 91/120\n",
      "1078/1078 [==============================] - 1s 806us/step - loss: 0.0292 - accuracy: 0.9128\n",
      "Epoch 92/120\n",
      "1078/1078 [==============================] - 1s 967us/step - loss: 0.0290 - accuracy: 0.9128\n",
      "Epoch 93/120\n",
      "1078/1078 [==============================] - 1s 832us/step - loss: 0.0288 - accuracy: 0.9137\n",
      "Epoch 94/120\n",
      "1078/1078 [==============================] - 1s 931us/step - loss: 0.0286 - accuracy: 0.9147\n",
      "Epoch 95/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0284 - accuracy: 0.9156\n",
      "Epoch 96/120\n",
      "1078/1078 [==============================] - 1s 816us/step - loss: 0.0282 - accuracy: 0.9165\n",
      "Epoch 97/120\n",
      "1078/1078 [==============================] - 1s 837us/step - loss: 0.0280 - accuracy: 0.9165\n",
      "Epoch 98/120\n",
      "1078/1078 [==============================] - 1s 810us/step - loss: 0.0278 - accuracy: 0.9174\n",
      "Epoch 99/120\n",
      "1078/1078 [==============================] - 1s 820us/step - loss: 0.0276 - accuracy: 0.9184\n",
      "Epoch 100/120\n",
      "1078/1078 [==============================] - 1s 796us/step - loss: 0.0274 - accuracy: 0.9184\n",
      "Epoch 101/120\n",
      "1078/1078 [==============================] - 1s 791us/step - loss: 0.0272 - accuracy: 0.9193\n",
      "Epoch 102/120\n",
      "1078/1078 [==============================] - 1s 897us/step - loss: 0.0270 - accuracy: 0.9193\n",
      "Epoch 103/120\n",
      "1078/1078 [==============================] - 1s 821us/step - loss: 0.0268 - accuracy: 0.9202\n",
      "Epoch 104/120\n",
      "1078/1078 [==============================] - 1s 967us/step - loss: 0.0266 - accuracy: 0.9212\n",
      "Epoch 105/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0264 - accuracy: 0.9230\n",
      "Epoch 106/120\n",
      "1078/1078 [==============================] - 1s 822us/step - loss: 0.0262 - accuracy: 0.9249\n",
      "Epoch 107/120\n",
      "1078/1078 [==============================] - 1s 792us/step - loss: 0.0261 - accuracy: 0.9239\n",
      "Epoch 108/120\n",
      "1078/1078 [==============================] - 1s 933us/step - loss: 0.0259 - accuracy: 0.9249\n",
      "Epoch 109/120\n",
      "1078/1078 [==============================] - 1s 822us/step - loss: 0.0257 - accuracy: 0.9249\n",
      "Epoch 110/120\n",
      "1078/1078 [==============================] - 1s 733us/step - loss: 0.0255 - accuracy: 0.9249\n",
      "Epoch 111/120\n",
      "1078/1078 [==============================] - 1s 797us/step - loss: 0.0253 - accuracy: 0.9286\n",
      "Epoch 112/120\n",
      "1078/1078 [==============================] - 1s 808us/step - loss: 0.0252 - accuracy: 0.9295\n",
      "Epoch 113/120\n",
      "1078/1078 [==============================] - 2s 1ms/step - loss: 0.0250 - accuracy: 0.9286\n",
      "Epoch 114/120\n",
      "1078/1078 [==============================] - 1s 1ms/step - loss: 0.0248 - accuracy: 0.9304\n",
      "Epoch 115/120\n",
      "1078/1078 [==============================] - 1s 818us/step - loss: 0.0246 - accuracy: 0.9314\n",
      "Epoch 116/120\n",
      "1078/1078 [==============================] - 1s 807us/step - loss: 0.0245 - accuracy: 0.9304\n",
      "Epoch 117/120\n",
      "1078/1078 [==============================] - 1s 833us/step - loss: 0.0243 - accuracy: 0.9332\n",
      "Epoch 118/120\n",
      "1078/1078 [==============================] - 1s 783us/step - loss: 0.0241 - accuracy: 0.9332\n",
      "Epoch 119/120\n",
      "1078/1078 [==============================] - 1s 818us/step - loss: 0.0240 - accuracy: 0.9351\n",
      "Epoch 120/120\n",
      "1078/1078 [==============================] - 1s 759us/step - loss: 0.0238 - accuracy: 0.9332\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13d42c7f0>"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "model.fit(X_train, y_v_train, epochs = 120, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0261 - accuracy: 0.9166\n",
      "Accuracy: 91.66\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(X_test, y_v_test)\n",
    "print('Accuracy: %.2f' % (accuracy[1]*100))"
   ]
  },
  {
   "source": [
    "# NN no extension (Wines dataset)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wines=load_wine()\n",
    "X = wines.data\n",
    "y = wines.target\n",
    "X_scale = StandardScaler()\n",
    "X = X_scale.fit_transform(wines.data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_y_to_vect(y):\n",
    "    y_vect = np.zeros((len(y), 3))\n",
    "    for i in range(len(y)):\n",
    "        y_vect[i, y[i]] = 1\n",
    "    return y_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert digits to vectors\n",
    "y_v_train = convert_y_to_vect(y_train)\n",
    "y_v_test = convert_y_to_vect(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The shape of the digits dataset:\n(106, 13)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of the digits dataset:\") \n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(13, activation=\"sigmoid\"))\n",
    "model.add(Dense(30, activation = \"sigmoid\"))\n",
    "model.add(Dense(3, activation = \"sigmoid\"))\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/120\n",
      "106/106 [==============================] - 0s 846us/step - loss: 0.2627 - accuracy: 0.4528\n",
      "Epoch 2/120\n",
      "106/106 [==============================] - 0s 807us/step - loss: 0.2383 - accuracy: 0.4623\n",
      "Epoch 3/120\n",
      "106/106 [==============================] - 0s 943us/step - loss: 0.2259 - accuracy: 0.4623\n",
      "Epoch 4/120\n",
      "106/106 [==============================] - 0s 853us/step - loss: 0.2196 - accuracy: 0.4623\n",
      "Epoch 5/120\n",
      "106/106 [==============================] - 0s 861us/step - loss: 0.2166 - accuracy: 0.4623\n",
      "Epoch 6/120\n",
      "106/106 [==============================] - 0s 862us/step - loss: 0.2149 - accuracy: 0.4623\n",
      "Epoch 7/120\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2138 - accuracy: 0.4623\n",
      "Epoch 8/120\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2131 - accuracy: 0.4623\n",
      "Epoch 9/120\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2126 - accuracy: 0.4623\n",
      "Epoch 10/120\n",
      "106/106 [==============================] - 0s 918us/step - loss: 0.2122 - accuracy: 0.4623\n",
      "Epoch 11/120\n",
      "106/106 [==============================] - 0s 864us/step - loss: 0.2118 - accuracy: 0.4623\n",
      "Epoch 12/120\n",
      "106/106 [==============================] - 0s 847us/step - loss: 0.2115 - accuracy: 0.4623\n",
      "Epoch 13/120\n",
      "106/106 [==============================] - 0s 800us/step - loss: 0.2112 - accuracy: 0.4623\n",
      "Epoch 14/120\n",
      "106/106 [==============================] - 0s 826us/step - loss: 0.2109 - accuracy: 0.4623\n",
      "Epoch 15/120\n",
      "106/106 [==============================] - 0s 884us/step - loss: 0.2106 - accuracy: 0.4623\n",
      "Epoch 16/120\n",
      "106/106 [==============================] - 0s 919us/step - loss: 0.2102 - accuracy: 0.4623\n",
      "Epoch 17/120\n",
      "106/106 [==============================] - 0s 873us/step - loss: 0.2100 - accuracy: 0.4623\n",
      "Epoch 18/120\n",
      "106/106 [==============================] - 0s 783us/step - loss: 0.2097 - accuracy: 0.4623\n",
      "Epoch 19/120\n",
      "106/106 [==============================] - 0s 926us/step - loss: 0.2094 - accuracy: 0.4623\n",
      "Epoch 20/120\n",
      "106/106 [==============================] - 0s 875us/step - loss: 0.2091 - accuracy: 0.4623\n",
      "Epoch 21/120\n",
      "106/106 [==============================] - 0s 937us/step - loss: 0.2087 - accuracy: 0.4623\n",
      "Epoch 22/120\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2084 - accuracy: 0.4623\n",
      "Epoch 23/120\n",
      "106/106 [==============================] - 0s 813us/step - loss: 0.2081 - accuracy: 0.4623\n",
      "Epoch 24/120\n",
      "106/106 [==============================] - 0s 816us/step - loss: 0.2077 - accuracy: 0.4623\n",
      "Epoch 25/120\n",
      "106/106 [==============================] - 0s 963us/step - loss: 0.2074 - accuracy: 0.4623\n",
      "Epoch 26/120\n",
      "106/106 [==============================] - 0s 872us/step - loss: 0.2072 - accuracy: 0.4623\n",
      "Epoch 27/120\n",
      "106/106 [==============================] - 0s 845us/step - loss: 0.2068 - accuracy: 0.4623\n",
      "Epoch 28/120\n",
      "106/106 [==============================] - 0s 899us/step - loss: 0.2065 - accuracy: 0.4623\n",
      "Epoch 29/120\n",
      "106/106 [==============================] - 0s 825us/step - loss: 0.2061 - accuracy: 0.4623\n",
      "Epoch 30/120\n",
      "106/106 [==============================] - 0s 811us/step - loss: 0.2058 - accuracy: 0.4623\n",
      "Epoch 31/120\n",
      "106/106 [==============================] - 0s 828us/step - loss: 0.2054 - accuracy: 0.4623\n",
      "Epoch 32/120\n",
      "106/106 [==============================] - 0s 774us/step - loss: 0.2051 - accuracy: 0.4623\n",
      "Epoch 33/120\n",
      "106/106 [==============================] - 0s 824us/step - loss: 0.2046 - accuracy: 0.4623\n",
      "Epoch 34/120\n",
      "106/106 [==============================] - 0s 887us/step - loss: 0.2043 - accuracy: 0.4623\n",
      "Epoch 35/120\n",
      "106/106 [==============================] - 0s 792us/step - loss: 0.2039 - accuracy: 0.4623\n",
      "Epoch 36/120\n",
      "106/106 [==============================] - 0s 908us/step - loss: 0.2035 - accuracy: 0.4623\n",
      "Epoch 37/120\n",
      "106/106 [==============================] - 0s 831us/step - loss: 0.2031 - accuracy: 0.4623\n",
      "Epoch 38/120\n",
      "106/106 [==============================] - 0s 828us/step - loss: 0.2028 - accuracy: 0.4623\n",
      "Epoch 39/120\n",
      "106/106 [==============================] - 0s 881us/step - loss: 0.2024 - accuracy: 0.4623\n",
      "Epoch 40/120\n",
      "106/106 [==============================] - 0s 843us/step - loss: 0.2019 - accuracy: 0.4623\n",
      "Epoch 41/120\n",
      "106/106 [==============================] - 0s 769us/step - loss: 0.2015 - accuracy: 0.4623\n",
      "Epoch 42/120\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.2011 - accuracy: 0.4623\n",
      "Epoch 43/120\n",
      "106/106 [==============================] - 0s 924us/step - loss: 0.2007 - accuracy: 0.4623\n",
      "Epoch 44/120\n",
      "106/106 [==============================] - 0s 793us/step - loss: 0.2002 - accuracy: 0.4623\n",
      "Epoch 45/120\n",
      "106/106 [==============================] - 0s 821us/step - loss: 0.1998 - accuracy: 0.4623\n",
      "Epoch 46/120\n",
      "106/106 [==============================] - 0s 831us/step - loss: 0.1993 - accuracy: 0.4623\n",
      "Epoch 47/120\n",
      "106/106 [==============================] - 0s 849us/step - loss: 0.1988 - accuracy: 0.4623\n",
      "Epoch 48/120\n",
      "106/106 [==============================] - 0s 831us/step - loss: 0.1983 - accuracy: 0.4623\n",
      "Epoch 49/120\n",
      "106/106 [==============================] - 0s 839us/step - loss: 0.1979 - accuracy: 0.4623\n",
      "Epoch 50/120\n",
      "106/106 [==============================] - 0s 839us/step - loss: 0.1973 - accuracy: 0.4623\n",
      "Epoch 51/120\n",
      "106/106 [==============================] - 0s 822us/step - loss: 0.1968 - accuracy: 0.4623\n",
      "Epoch 52/120\n",
      "106/106 [==============================] - 0s 880us/step - loss: 0.1963 - accuracy: 0.4623\n",
      "Epoch 53/120\n",
      "106/106 [==============================] - 0s 886us/step - loss: 0.1958 - accuracy: 0.4623\n",
      "Epoch 54/120\n",
      "106/106 [==============================] - 0s 870us/step - loss: 0.1952 - accuracy: 0.4623\n",
      "Epoch 55/120\n",
      "106/106 [==============================] - 0s 820us/step - loss: 0.1947 - accuracy: 0.4623\n",
      "Epoch 56/120\n",
      "106/106 [==============================] - 0s 796us/step - loss: 0.1941 - accuracy: 0.4623\n",
      "Epoch 57/120\n",
      "106/106 [==============================] - 0s 840us/step - loss: 0.1935 - accuracy: 0.4623\n",
      "Epoch 58/120\n",
      "106/106 [==============================] - 0s 873us/step - loss: 0.1929 - accuracy: 0.4717\n",
      "Epoch 59/120\n",
      "106/106 [==============================] - 0s 898us/step - loss: 0.1924 - accuracy: 0.4623\n",
      "Epoch 60/120\n",
      "106/106 [==============================] - 0s 922us/step - loss: 0.1917 - accuracy: 0.4623\n",
      "Epoch 61/120\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1911 - accuracy: 0.4717\n",
      "Epoch 62/120\n",
      "106/106 [==============================] - 0s 818us/step - loss: 0.1905 - accuracy: 0.4717\n",
      "Epoch 63/120\n",
      "106/106 [==============================] - 0s 858us/step - loss: 0.1898 - accuracy: 0.4811\n",
      "Epoch 64/120\n",
      "106/106 [==============================] - 0s 784us/step - loss: 0.1892 - accuracy: 0.4811\n",
      "Epoch 65/120\n",
      "106/106 [==============================] - 0s 847us/step - loss: 0.1885 - accuracy: 0.4811\n",
      "Epoch 66/120\n",
      "106/106 [==============================] - 0s 838us/step - loss: 0.1878 - accuracy: 0.5094\n",
      "Epoch 67/120\n",
      "106/106 [==============================] - 0s 872us/step - loss: 0.1871 - accuracy: 0.5094\n",
      "Epoch 68/120\n",
      "106/106 [==============================] - 0s 829us/step - loss: 0.1863 - accuracy: 0.5377\n",
      "Epoch 69/120\n",
      "106/106 [==============================] - 0s 995us/step - loss: 0.1857 - accuracy: 0.5094\n",
      "Epoch 70/120\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1849 - accuracy: 0.5189\n",
      "Epoch 71/120\n",
      "106/106 [==============================] - 0s 856us/step - loss: 0.1841 - accuracy: 0.5755\n",
      "Epoch 72/120\n",
      "106/106 [==============================] - 0s 825us/step - loss: 0.1834 - accuracy: 0.5189\n",
      "Epoch 73/120\n",
      "106/106 [==============================] - 0s 957us/step - loss: 0.1826 - accuracy: 0.5660\n",
      "Epoch 74/120\n",
      "106/106 [==============================] - 0s 798us/step - loss: 0.1818 - accuracy: 0.5660\n",
      "Epoch 75/120\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1810 - accuracy: 0.5755\n",
      "Epoch 76/120\n",
      "106/106 [==============================] - 0s 824us/step - loss: 0.1802 - accuracy: 0.5660\n",
      "Epoch 77/120\n",
      "106/106 [==============================] - 0s 782us/step - loss: 0.1793 - accuracy: 0.5943\n",
      "Epoch 78/120\n",
      "106/106 [==============================] - 0s 871us/step - loss: 0.1784 - accuracy: 0.6132\n",
      "Epoch 79/120\n",
      "106/106 [==============================] - 0s 803us/step - loss: 0.1776 - accuracy: 0.5943\n",
      "Epoch 80/120\n",
      "106/106 [==============================] - 0s 799us/step - loss: 0.1767 - accuracy: 0.6321\n",
      "Epoch 81/120\n",
      "106/106 [==============================] - 0s 957us/step - loss: 0.1758 - accuracy: 0.6321\n",
      "Epoch 82/120\n",
      "106/106 [==============================] - 0s 835us/step - loss: 0.1749 - accuracy: 0.6509\n",
      "Epoch 83/120\n",
      "106/106 [==============================] - 0s 859us/step - loss: 0.1740 - accuracy: 0.6509\n",
      "Epoch 84/120\n",
      "106/106 [==============================] - 0s 786us/step - loss: 0.1730 - accuracy: 0.6415\n",
      "Epoch 85/120\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1721 - accuracy: 0.6509\n",
      "Epoch 86/120\n",
      "106/106 [==============================] - 0s 896us/step - loss: 0.1711 - accuracy: 0.6509\n",
      "Epoch 87/120\n",
      "106/106 [==============================] - 0s 928us/step - loss: 0.1701 - accuracy: 0.6509\n",
      "Epoch 88/120\n",
      "106/106 [==============================] - 0s 963us/step - loss: 0.1691 - accuracy: 0.6509\n",
      "Epoch 89/120\n",
      "106/106 [==============================] - 0s 918us/step - loss: 0.1681 - accuracy: 0.6792\n",
      "Epoch 90/120\n",
      "106/106 [==============================] - 0s 808us/step - loss: 0.1671 - accuracy: 0.6604\n",
      "Epoch 91/120\n",
      "106/106 [==============================] - 0s 919us/step - loss: 0.1660 - accuracy: 0.6698\n",
      "Epoch 92/120\n",
      "106/106 [==============================] - 0s 938us/step - loss: 0.1650 - accuracy: 0.6792\n",
      "Epoch 93/120\n",
      "106/106 [==============================] - 0s 911us/step - loss: 0.1640 - accuracy: 0.6698\n",
      "Epoch 94/120\n",
      "106/106 [==============================] - 0s 927us/step - loss: 0.1629 - accuracy: 0.6698\n",
      "Epoch 95/120\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1618 - accuracy: 0.6698\n",
      "Epoch 96/120\n",
      "106/106 [==============================] - 0s 868us/step - loss: 0.1607 - accuracy: 0.6698\n",
      "Epoch 97/120\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1596 - accuracy: 0.6698\n",
      "Epoch 98/120\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1585 - accuracy: 0.6792\n",
      "Epoch 99/120\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.1574 - accuracy: 0.6698\n",
      "Epoch 100/120\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1563 - accuracy: 0.6698\n",
      "Epoch 101/120\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1551 - accuracy: 0.6981\n",
      "Epoch 102/120\n",
      "106/106 [==============================] - 0s 908us/step - loss: 0.1540 - accuracy: 0.6981\n",
      "Epoch 103/120\n",
      "106/106 [==============================] - 0s 907us/step - loss: 0.1529 - accuracy: 0.6981\n",
      "Epoch 104/120\n",
      "106/106 [==============================] - 0s 854us/step - loss: 0.1517 - accuracy: 0.7075\n",
      "Epoch 105/120\n",
      "106/106 [==============================] - 0s 851us/step - loss: 0.1505 - accuracy: 0.7075\n",
      "Epoch 106/120\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1494 - accuracy: 0.7547\n",
      "Epoch 107/120\n",
      "106/106 [==============================] - 0s 901us/step - loss: 0.1482 - accuracy: 0.7264\n",
      "Epoch 108/120\n",
      "106/106 [==============================] - 0s 840us/step - loss: 0.1470 - accuracy: 0.7642\n",
      "Epoch 109/120\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.1457 - accuracy: 0.8868\n",
      "Epoch 110/120\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1446 - accuracy: 0.8113\n",
      "Epoch 111/120\n",
      "106/106 [==============================] - 0s 944us/step - loss: 0.1434 - accuracy: 0.8302\n",
      "Epoch 112/120\n",
      "106/106 [==============================] - 0s 861us/step - loss: 0.1422 - accuracy: 0.8302\n",
      "Epoch 113/120\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.1410 - accuracy: 0.8208\n",
      "Epoch 114/120\n",
      "106/106 [==============================] - 0s 906us/step - loss: 0.1398 - accuracy: 0.8585\n",
      "Epoch 115/120\n",
      "106/106 [==============================] - 0s 796us/step - loss: 0.1386 - accuracy: 0.8679\n",
      "Epoch 116/120\n",
      "106/106 [==============================] - 0s 863us/step - loss: 0.1374 - accuracy: 0.8868\n",
      "Epoch 117/120\n",
      "106/106 [==============================] - 0s 838us/step - loss: 0.1362 - accuracy: 0.9057\n",
      "Epoch 118/120\n",
      "106/106 [==============================] - 0s 937us/step - loss: 0.1349 - accuracy: 0.8868\n",
      "Epoch 119/120\n",
      "106/106 [==============================] - 0s 947us/step - loss: 0.1337 - accuracy: 0.9057\n",
      "Epoch 120/120\n",
      "106/106 [==============================] - 0s 776us/step - loss: 0.1325 - accuracy: 0.8868\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13d47dd30>"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "model.fit(X_train, y_v_train, epochs = 120, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3/3 [==============================] - 0s 827us/step - loss: 0.1379 - accuracy: 0.9028\n",
      "Accuracy: 90.28\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(X_test, y_v_test)\n",
    "print('Accuracy: %.2f' % (accuracy[1]*100))"
   ]
  },
  {
   "source": [
    "# NN with softmax extension (Wines dataset)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_model = Sequential()\n",
    "softmax_model.add(Dense(13, activation=\"sigmoid\"))\n",
    "softmax_model.add(Dense(30, activation = \"sigmoid\"))\n",
    "softmax_model.add(Dense(3, activation = \"softmax\"))\n",
    "softmax_model.compile(loss='mean_squared_error', optimizer='sgd', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/120\n",
      "106/106 [==============================] - 0s 796us/step - loss: 0.2191 - accuracy: 0.4057\n",
      "Epoch 2/120\n",
      "106/106 [==============================] - 0s 773us/step - loss: 0.2113 - accuracy: 0.4623\n",
      "Epoch 3/120\n",
      "106/106 [==============================] - 0s 664us/step - loss: 0.2075 - accuracy: 0.4623\n",
      "Epoch 4/120\n",
      "106/106 [==============================] - 0s 920us/step - loss: 0.2054 - accuracy: 0.4623\n",
      "Epoch 5/120\n",
      "106/106 [==============================] - 0s 958us/step - loss: 0.2039 - accuracy: 0.4623\n",
      "Epoch 6/120\n",
      "106/106 [==============================] - 0s 746us/step - loss: 0.2027 - accuracy: 0.4623\n",
      "Epoch 7/120\n",
      "106/106 [==============================] - 0s 691us/step - loss: 0.2015 - accuracy: 0.4623\n",
      "Epoch 8/120\n",
      "106/106 [==============================] - 0s 668us/step - loss: 0.2005 - accuracy: 0.4623\n",
      "Epoch 9/120\n",
      "106/106 [==============================] - 0s 764us/step - loss: 0.1993 - accuracy: 0.4623\n",
      "Epoch 10/120\n",
      "106/106 [==============================] - 0s 652us/step - loss: 0.1980 - accuracy: 0.4623\n",
      "Epoch 11/120\n",
      "106/106 [==============================] - 0s 658us/step - loss: 0.1970 - accuracy: 0.4623\n",
      "Epoch 12/120\n",
      "106/106 [==============================] - 0s 655us/step - loss: 0.1958 - accuracy: 0.4623\n",
      "Epoch 13/120\n",
      "106/106 [==============================] - 0s 663us/step - loss: 0.1944 - accuracy: 0.4623\n",
      "Epoch 14/120\n",
      "106/106 [==============================] - 0s 689us/step - loss: 0.1934 - accuracy: 0.4623\n",
      "Epoch 15/120\n",
      "106/106 [==============================] - 0s 671us/step - loss: 0.1920 - accuracy: 0.4623\n",
      "Epoch 16/120\n",
      "106/106 [==============================] - 0s 658us/step - loss: 0.1903 - accuracy: 0.4623\n",
      "Epoch 17/120\n",
      "106/106 [==============================] - 0s 629us/step - loss: 0.1893 - accuracy: 0.4623\n",
      "Epoch 18/120\n",
      "106/106 [==============================] - 0s 628us/step - loss: 0.1880 - accuracy: 0.4623\n",
      "Epoch 19/120\n",
      "106/106 [==============================] - 0s 653us/step - loss: 0.1856 - accuracy: 0.4623\n",
      "Epoch 20/120\n",
      "106/106 [==============================] - 0s 697us/step - loss: 0.1853 - accuracy: 0.4623\n",
      "Epoch 21/120\n",
      "106/106 [==============================] - 0s 646us/step - loss: 0.1837 - accuracy: 0.4717\n",
      "Epoch 22/120\n",
      "106/106 [==============================] - 0s 684us/step - loss: 0.1819 - accuracy: 0.4906\n",
      "Epoch 23/120\n",
      "106/106 [==============================] - 0s 622us/step - loss: 0.1804 - accuracy: 0.4623\n",
      "Epoch 24/120\n",
      "106/106 [==============================] - 0s 705us/step - loss: 0.1789 - accuracy: 0.4811\n",
      "Epoch 25/120\n",
      "106/106 [==============================] - 0s 634us/step - loss: 0.1774 - accuracy: 0.5094\n",
      "Epoch 26/120\n",
      "106/106 [==============================] - 0s 684us/step - loss: 0.1758 - accuracy: 0.4906\n",
      "Epoch 27/120\n",
      "106/106 [==============================] - 0s 635us/step - loss: 0.1739 - accuracy: 0.4906\n",
      "Epoch 28/120\n",
      "106/106 [==============================] - 0s 710us/step - loss: 0.1725 - accuracy: 0.5472\n",
      "Epoch 29/120\n",
      "106/106 [==============================] - 0s 628us/step - loss: 0.1707 - accuracy: 0.5755\n",
      "Epoch 30/120\n",
      "106/106 [==============================] - 0s 655us/step - loss: 0.1689 - accuracy: 0.6132\n",
      "Epoch 31/120\n",
      "106/106 [==============================] - 0s 649us/step - loss: 0.1669 - accuracy: 0.5377\n",
      "Epoch 32/120\n",
      "106/106 [==============================] - 0s 629us/step - loss: 0.1652 - accuracy: 0.6792\n",
      "Epoch 33/120\n",
      "106/106 [==============================] - 0s 649us/step - loss: 0.1636 - accuracy: 0.6226\n",
      "Epoch 34/120\n",
      "106/106 [==============================] - 0s 660us/step - loss: 0.1618 - accuracy: 0.6887\n",
      "Epoch 35/120\n",
      "106/106 [==============================] - 0s 702us/step - loss: 0.1599 - accuracy: 0.6321\n",
      "Epoch 36/120\n",
      "106/106 [==============================] - 0s 627us/step - loss: 0.1581 - accuracy: 0.6887\n",
      "Epoch 37/120\n",
      "106/106 [==============================] - 0s 665us/step - loss: 0.1561 - accuracy: 0.7547\n",
      "Epoch 38/120\n",
      "106/106 [==============================] - 0s 648us/step - loss: 0.1544 - accuracy: 0.7170\n",
      "Epoch 39/120\n",
      "106/106 [==============================] - 0s 688us/step - loss: 0.1525 - accuracy: 0.7170\n",
      "Epoch 40/120\n",
      "106/106 [==============================] - 0s 637us/step - loss: 0.1506 - accuracy: 0.7642\n",
      "Epoch 41/120\n",
      "106/106 [==============================] - 0s 695us/step - loss: 0.1488 - accuracy: 0.7358\n",
      "Epoch 42/120\n",
      "106/106 [==============================] - 0s 668us/step - loss: 0.1469 - accuracy: 0.8302\n",
      "Epoch 43/120\n",
      "106/106 [==============================] - 0s 645us/step - loss: 0.1452 - accuracy: 0.7642\n",
      "Epoch 44/120\n",
      "106/106 [==============================] - 0s 651us/step - loss: 0.1434 - accuracy: 0.7830\n",
      "Epoch 45/120\n",
      "106/106 [==============================] - 0s 684us/step - loss: 0.1416 - accuracy: 0.8113\n",
      "Epoch 46/120\n",
      "106/106 [==============================] - 0s 651us/step - loss: 0.1398 - accuracy: 0.8302\n",
      "Epoch 47/120\n",
      "106/106 [==============================] - 0s 691us/step - loss: 0.1380 - accuracy: 0.8302\n",
      "Epoch 48/120\n",
      "106/106 [==============================] - 0s 629us/step - loss: 0.1364 - accuracy: 0.8679\n",
      "Epoch 49/120\n",
      "106/106 [==============================] - 0s 630us/step - loss: 0.1347 - accuracy: 0.8679\n",
      "Epoch 50/120\n",
      "106/106 [==============================] - 0s 688us/step - loss: 0.1330 - accuracy: 0.8585\n",
      "Epoch 51/120\n",
      "106/106 [==============================] - 0s 631us/step - loss: 0.1313 - accuracy: 0.8868\n",
      "Epoch 52/120\n",
      "106/106 [==============================] - 0s 662us/step - loss: 0.1296 - accuracy: 0.8491\n",
      "Epoch 53/120\n",
      "106/106 [==============================] - 0s 652us/step - loss: 0.1281 - accuracy: 0.8774\n",
      "Epoch 54/120\n",
      "106/106 [==============================] - 0s 661us/step - loss: 0.1265 - accuracy: 0.8679\n",
      "Epoch 55/120\n",
      "106/106 [==============================] - 0s 645us/step - loss: 0.1250 - accuracy: 0.8774\n",
      "Epoch 56/120\n",
      "106/106 [==============================] - 0s 713us/step - loss: 0.1235 - accuracy: 0.8774\n",
      "Epoch 57/120\n",
      "106/106 [==============================] - 0s 678us/step - loss: 0.1219 - accuracy: 0.9057\n",
      "Epoch 58/120\n",
      "106/106 [==============================] - 0s 676us/step - loss: 0.1205 - accuracy: 0.9151\n",
      "Epoch 59/120\n",
      "106/106 [==============================] - 0s 648us/step - loss: 0.1190 - accuracy: 0.8962\n",
      "Epoch 60/120\n",
      "106/106 [==============================] - 0s 652us/step - loss: 0.1176 - accuracy: 0.9057\n",
      "Epoch 61/120\n",
      "106/106 [==============================] - 0s 692us/step - loss: 0.1162 - accuracy: 0.9057\n",
      "Epoch 62/120\n",
      "106/106 [==============================] - 0s 740us/step - loss: 0.1148 - accuracy: 0.9340\n",
      "Epoch 63/120\n",
      "106/106 [==============================] - 0s 684us/step - loss: 0.1134 - accuracy: 0.9434\n",
      "Epoch 64/120\n",
      "106/106 [==============================] - 0s 669us/step - loss: 0.1121 - accuracy: 0.9245\n",
      "Epoch 65/120\n",
      "106/106 [==============================] - 0s 679us/step - loss: 0.1107 - accuracy: 0.9245\n",
      "Epoch 66/120\n",
      "106/106 [==============================] - 0s 653us/step - loss: 0.1094 - accuracy: 0.9528\n",
      "Epoch 67/120\n",
      "106/106 [==============================] - 0s 658us/step - loss: 0.1081 - accuracy: 0.9528\n",
      "Epoch 68/120\n",
      "106/106 [==============================] - 0s 681us/step - loss: 0.1068 - accuracy: 0.9340\n",
      "Epoch 69/120\n",
      "106/106 [==============================] - 0s 659us/step - loss: 0.1054 - accuracy: 0.9340\n",
      "Epoch 70/120\n",
      "106/106 [==============================] - 0s 703us/step - loss: 0.1041 - accuracy: 0.9434\n",
      "Epoch 71/120\n",
      "106/106 [==============================] - 0s 677us/step - loss: 0.1029 - accuracy: 0.9434\n",
      "Epoch 72/120\n",
      "106/106 [==============================] - 0s 682us/step - loss: 0.1015 - accuracy: 0.9623\n",
      "Epoch 73/120\n",
      "106/106 [==============================] - 0s 633us/step - loss: 0.0999 - accuracy: 0.9245\n",
      "Epoch 74/120\n",
      "106/106 [==============================] - 0s 689us/step - loss: 0.0990 - accuracy: 0.9623\n",
      "Epoch 75/120\n",
      "106/106 [==============================] - 0s 727us/step - loss: 0.0977 - accuracy: 0.9623\n",
      "Epoch 76/120\n",
      "106/106 [==============================] - 0s 644us/step - loss: 0.0963 - accuracy: 0.9623\n",
      "Epoch 77/120\n",
      "106/106 [==============================] - 0s 657us/step - loss: 0.0950 - accuracy: 0.9528\n",
      "Epoch 78/120\n",
      "106/106 [==============================] - 0s 720us/step - loss: 0.0937 - accuracy: 0.9623\n",
      "Epoch 79/120\n",
      "106/106 [==============================] - 0s 678us/step - loss: 0.0924 - accuracy: 0.9623\n",
      "Epoch 80/120\n",
      "106/106 [==============================] - 0s 799us/step - loss: 0.0911 - accuracy: 0.9623\n",
      "Epoch 81/120\n",
      "106/106 [==============================] - 0s 768us/step - loss: 0.0897 - accuracy: 0.9623\n",
      "Epoch 82/120\n",
      "106/106 [==============================] - 0s 673us/step - loss: 0.0885 - accuracy: 0.9623\n",
      "Epoch 83/120\n",
      "106/106 [==============================] - 0s 777us/step - loss: 0.0871 - accuracy: 0.9623\n",
      "Epoch 84/120\n",
      "106/106 [==============================] - 0s 776us/step - loss: 0.0856 - accuracy: 0.9623\n",
      "Epoch 85/120\n",
      "106/106 [==============================] - 0s 665us/step - loss: 0.0843 - accuracy: 0.9623\n",
      "Epoch 86/120\n",
      "106/106 [==============================] - 0s 737us/step - loss: 0.0829 - accuracy: 0.9623\n",
      "Epoch 87/120\n",
      "106/106 [==============================] - 0s 682us/step - loss: 0.0815 - accuracy: 0.9623\n",
      "Epoch 88/120\n",
      "106/106 [==============================] - 0s 697us/step - loss: 0.0800 - accuracy: 0.9623\n",
      "Epoch 89/120\n",
      "106/106 [==============================] - 0s 694us/step - loss: 0.0787 - accuracy: 0.9717\n",
      "Epoch 90/120\n",
      "106/106 [==============================] - 0s 659us/step - loss: 0.0773 - accuracy: 0.9717\n",
      "Epoch 91/120\n",
      "106/106 [==============================] - 0s 697us/step - loss: 0.0758 - accuracy: 0.9811\n",
      "Epoch 92/120\n",
      "106/106 [==============================] - 0s 684us/step - loss: 0.0744 - accuracy: 0.9717\n",
      "Epoch 93/120\n",
      "106/106 [==============================] - 0s 718us/step - loss: 0.0729 - accuracy: 0.9717\n",
      "Epoch 94/120\n",
      "106/106 [==============================] - 0s 674us/step - loss: 0.0715 - accuracy: 0.9811\n",
      "Epoch 95/120\n",
      "106/106 [==============================] - 0s 668us/step - loss: 0.0700 - accuracy: 0.9811\n",
      "Epoch 96/120\n",
      "106/106 [==============================] - 0s 651us/step - loss: 0.0685 - accuracy: 0.9811\n",
      "Epoch 97/120\n",
      "106/106 [==============================] - 0s 702us/step - loss: 0.0669 - accuracy: 0.9811\n",
      "Epoch 98/120\n",
      "106/106 [==============================] - 0s 658us/step - loss: 0.0656 - accuracy: 0.9811\n",
      "Epoch 99/120\n",
      "106/106 [==============================] - 0s 658us/step - loss: 0.0641 - accuracy: 0.9811\n",
      "Epoch 100/120\n",
      "106/106 [==============================] - 0s 735us/step - loss: 0.0626 - accuracy: 0.9811\n",
      "Epoch 101/120\n",
      "106/106 [==============================] - 0s 727us/step - loss: 0.0612 - accuracy: 0.9811\n",
      "Epoch 102/120\n",
      "106/106 [==============================] - 0s 680us/step - loss: 0.0598 - accuracy: 0.9811\n",
      "Epoch 103/120\n",
      "106/106 [==============================] - 0s 731us/step - loss: 0.0583 - accuracy: 0.9811\n",
      "Epoch 104/120\n",
      "106/106 [==============================] - 0s 736us/step - loss: 0.0570 - accuracy: 0.9811\n",
      "Epoch 105/120\n",
      "106/106 [==============================] - 0s 753us/step - loss: 0.0555 - accuracy: 0.9811\n",
      "Epoch 106/120\n",
      "106/106 [==============================] - 0s 700us/step - loss: 0.0542 - accuracy: 0.9811\n",
      "Epoch 107/120\n",
      "106/106 [==============================] - 0s 697us/step - loss: 0.0528 - accuracy: 0.9811\n",
      "Epoch 108/120\n",
      "106/106 [==============================] - 0s 657us/step - loss: 0.0515 - accuracy: 0.9811\n",
      "Epoch 109/120\n",
      "106/106 [==============================] - 0s 2ms/step - loss: 0.0502 - accuracy: 0.9811\n",
      "Epoch 110/120\n",
      "106/106 [==============================] - 0s 767us/step - loss: 0.0489 - accuracy: 0.9811\n",
      "Epoch 111/120\n",
      "106/106 [==============================] - 0s 720us/step - loss: 0.0476 - accuracy: 0.9811\n",
      "Epoch 112/120\n",
      "106/106 [==============================] - 0s 899us/step - loss: 0.0464 - accuracy: 0.9811\n",
      "Epoch 113/120\n",
      "106/106 [==============================] - 0s 972us/step - loss: 0.0453 - accuracy: 0.9811\n",
      "Epoch 114/120\n",
      "106/106 [==============================] - 0s 1ms/step - loss: 0.0441 - accuracy: 0.9811\n",
      "Epoch 115/120\n",
      "106/106 [==============================] - 0s 993us/step - loss: 0.0430 - accuracy: 0.9811\n",
      "Epoch 116/120\n",
      "106/106 [==============================] - 0s 858us/step - loss: 0.0419 - accuracy: 0.9811\n",
      "Epoch 117/120\n",
      "106/106 [==============================] - 0s 717us/step - loss: 0.0408 - accuracy: 0.9811\n",
      "Epoch 118/120\n",
      "106/106 [==============================] - 0s 669us/step - loss: 0.0398 - accuracy: 0.9811\n",
      "Epoch 119/120\n",
      "106/106 [==============================] - 0s 697us/step - loss: 0.0388 - accuracy: 0.9811\n",
      "Epoch 120/120\n",
      "106/106 [==============================] - 0s 691us/step - loss: 0.0378 - accuracy: 0.9811\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13d54fdc0>"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "softmax_model.fit(X_train, y_v_train, epochs = 120, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0544 - accuracy: 0.9861\n",
      "Accuracy: 98.61\n"
     ]
    }
   ],
   "source": [
    "accuracy = softmax_model.evaluate(X_test, y_v_test)\n",
    "print('Accuracy: %.2f' % (accuracy[1]*100))"
   ]
  }
 ]
}